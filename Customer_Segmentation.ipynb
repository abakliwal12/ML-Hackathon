{"cells":[{"metadata":{"_cell_guid":"77841518-29e7-4001-9aeb-6267400da121","_uuid":"baf39e29f412685d42adbf39a6030e5f00255d0d"},"cell_type":"markdown","source":"We analyse the Buying Pattern of a customer based on E-commerce dataset that lists purchases made by 4000 customers over a period of one year (from 2010/12/01 to 2011/12/09). We first cluster products and customers to find the probable categories of the same. Then, we train a classifier using the assigned category as the target column. Finally, this model is used for making customer category predictions."},{"metadata":{"_cell_guid":"705714b1-870b-4f34-b5bf-cd027dafaefe","_kg_hide-input":true,"_uuid":"bb40a7b23734d82876d812fab6daecd83a46368c","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport pickle\nimport dill\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime, nltk, warnings\nimport matplotlib.cm as cm\nimport itertools\nfrom kmodes.kmodes import KModes\nfrom pathlib import Path\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn import preprocessing, model_selection, metrics, feature_selection\nfrom sklearn.model_selection import GridSearchCV, learning_curve\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import linear_model\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.decomposition import PCA\nfrom IPython.display import display, HTML\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\nwarnings.filterwarnings(\"ignore\")\nplt.rcParams[\"patch.force_edgecolor\"] = True\nplt.style.use('fivethirtyeight')\nmpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1063f9e0-e494-4873-939f-8aa5ca40cc89","_kg_hide-input":true,"_uuid":"227fc0cb1d5216d52e057e1d2d7debd0e29abe46","scrolled":false,"trusted":true},"cell_type":"code","source":"# read the datafile\ndf_initial = pd.read_csv('/kaggle/input/ecommerce-data/data.csv',encoding=\"ISO-8859-1\", dtype={'CustomerID': str,'InvoiceID': str})\nprint('Dataframe dimensions:', df_initial.shape)\n\n# The date format in the original data does not match the one used by pandas.\n# Hence we convert the InvoiceDate column to dataframe.\ndf_initial['InvoiceDate'] = pd.to_datetime(df_initial['InvoiceDate'])\n\ndisplay(df_initial.info())\ndisplay(df_initial.describe())\n\ndisplay(df_initial[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We observe that there are only about 400,000 non-null values in CustomerID. Since, we don't have enough data for imputing these values, we remove the corresponding rows."},{"metadata":{"_cell_guid":"f9de6b67-a588-43ab-8f51-b28efdee9e32","_kg_hide-input":true,"_uuid":"9b915fa18b311e8f93ac862bd49d08d90e03ca48","trusted":true},"cell_type":"code","source":"df_initial.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\nprint('Dataframe dimensions:', df_initial.shape)\n\ndisplay(df_initial.info())\ndisplay(df_initial.describe())\n\ndisplay(df_initial[:5])\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"baf1ff2e-646b-468b-b7b4-68343f388387","_uuid":"6b988d1dee3deecafd54f2b3555d1f84b509d213","trusted":true},"cell_type":"code","source":"# removing duplicate entries\nprint('Duplicate Entries: {}'.format(df_initial.duplicated().sum()))\ndf_initial.drop_duplicates(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"677f103d-d199-480c-bca4-fc08f7aa2e92","_kg_hide-input":true,"_uuid":"dc2f4b48b76615721e6718efbd31fcd3faf16bec","trusted":true},"cell_type":"code","source":"# checking the number of products, transactions and customers\npd.DataFrame([{'products': len(df_initial['StockCode'].value_counts()),    \n               'transactions': len(df_initial['InvoiceNo'].value_counts()),\n               'customers': len(df_initial['CustomerID'].value_counts()),  \n              }], columns = ['products', 'transactions', 'customers'], index = ['quantity'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"72d6dede-4280-4afd-b61b-085ea8c73d67","_kg_hide-input":true,"_uuid":"dd0d84bd4275a04e361b5b41924d11b7f6f2e9ff","trusted":true},"cell_type":"code","source":"# checking number of products purchased in every transaction\ntemp = df_initial.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate'].count()\nnb_products_per_basket = temp.rename(columns = {'InvoiceDate':'Number of products'})\nnb_products_per_basket[:10].sort_values('CustomerID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We infer the following\n    1. Some customers buy many items in a transaction\n    2. Cancellation transactions have InvoiceNo starting with 'C'    "},{"metadata":{"_cell_guid":"9b0e32d8-fc9c-4301-ac18-9c1d7cc5b54f","_kg_hide-input":true,"_uuid":"076fba25ed8a2b38fddd83ff862fa21e7f790a11","trusted":true},"cell_type":"code","source":"nb_products_per_basket['order_canceled'] = nb_products_per_basket['InvoiceNo'].apply(lambda x:int('C' in x))\ndisplay(nb_products_per_basket[:5])\n\nn1 = nb_products_per_basket['order_canceled'].sum()\nn2 = nb_products_per_basket.shape[0]\nprint('Number of orders cancelled: {}/{} ({:.2f}%) '.format(n1, n2, n1/n2*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the data, we observe that Quantity may be negative in one of the following two cases:\n    1. The transaction is a discounted transaction.\n    2. The transaction is a cancellation transaction.\n        a. Without a counterpart.\n        b. With atleast one counterpart."},{"metadata":{"_cell_guid":"af540729-739b-45b3-858f-f1facf9f8ae6","_kg_hide-input":true,"_uuid":"6f5c10794e09eb3d0dc83889d74b2029d6d24756","trusted":true},"cell_type":"code","source":"df_cleaned = df_initial.copy(deep = True)\ndf_cleaned['QuantityCancelled'] = 0\n\nentry_to_remove = [] ; doubtful_entry = []\n\nfor index, col in  df_initial.iterrows():\n    if (col['Quantity'] > 0) or col['Description'] == 'Discount': \n        continue        \n    df_test = df_initial[(df_initial['CustomerID'] == col['CustomerID']) &\n                         (df_initial['StockCode']  == col['StockCode']) & \n                         (df_initial['InvoiceDate'] < col['InvoiceDate']) & \n                         (df_initial['Quantity']   > 0)].copy()\n    \n    # Cancelation WITHOUT counterpart\n    if (df_test.shape[0] == 0): \n        doubtful_entry.append(index)\n    \n    # Cancelation WITH a counterpart\n    elif (df_test.shape[0] == 1): \n        index_order = df_test.index[0]\n        df_cleaned.loc[index_order, 'QuantityCancelled'] = -col['Quantity']\n        entry_to_remove.append(index)        \n    \n    # Various counterparts exist in orders: we delete the last one\n    elif (df_test.shape[0] > 1): \n        df_test.sort_index(axis=0 ,ascending=False, inplace = True)        \n        for ind, val in df_test.iterrows():\n            if val['Quantity'] < -col['Quantity']: continue\n            df_cleaned.loc[ind, 'QuantityCancelled'] = -col['Quantity']\n            entry_to_remove.append(index) \n            break            \n            ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f1d3a68d-fa59-4671-8be1-cdbb646ce13f","_kg_hide-input":true,"_uuid":"d98a0917de35db7afe31c69c324cd32e934edd52","scrolled":true,"trusted":true},"cell_type":"code","source":"#dropping entries\nprint(\"entry_to_remove: {}\".format(len(entry_to_remove)))\nprint(\"doubtful_entry: {}\".format(len(doubtful_entry)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"50f6c074-08cc-4c55-8285-d674d0d84b45","_kg_hide-input":true,"_uuid":"c523275748742927f689725305e90ae6fdeb4136","trusted":true},"cell_type":"code","source":"df_cleaned.drop(entry_to_remove, axis = 0, inplace = True)\ndf_cleaned.drop(doubtfull_entry, axis = 0, inplace = True)\nremaining_entries = df_cleaned[(df_cleaned['Quantity'] < 0) & (df_cleaned['StockCode'] != 'D')]\nprint(\"No of entries to delete: {}\".format(remaining_entries.shape[0]))\nremaining_entries[:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e00212c8-5c1e-4dda-a392-cbc68c1964b1","_kg_hide-input":true,"_uuid":"57e546917a0ea9a59a0e1dc3e0f9179c7efa66b5","scrolled":true,"trusted":true},"cell_type":"code","source":"list_special_codes = df_cleaned[df_cleaned['StockCode'].str.contains('^[a-zA-Z]+', regex=True)]['StockCode'].unique()\nlist_special_codes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a225335-7d6e-4c5b-a874-801e3f329f10","_kg_hide-input":true,"_uuid":"ce078be30fea360c161b449a8cb666d98808e936","trusted":true},"cell_type":"code","source":"for code in list_special_codes:\n    print(\"{:<15} -> {:<30}\".format(code, df_cleaned[df_cleaned['StockCode'] == code]['Description'].unique()[0]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3cbf20c0-0a44-49dc-96c3-ffd5455ddf0b","_kg_hide-input":true,"_uuid":"5f070241e41d989ed3de0769d9f35f330d086415","trusted":true},"cell_type":"code","source":"# finding total price of every transaction\ndf_cleaned['TotalPrice'] = df_cleaned['UnitPrice'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCancelled'])\ndf_cleaned.sort_values('CustomerID')[:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e4530b2-addf-4dc7-9ca8-065c26b73023","_kg_hide-input":true,"_uuid":"653fd7be2e985cf4578af4306f40948926fb60b3","trusted":true},"cell_type":"code","source":"# sum of purchases / user & order\ntemp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\nbasket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\n\n# date of the order\ndf_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\ntemp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\ndf_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\nbasket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])\n\n# selection of significant entries\nbasket_price = basket_price[basket_price['Basket Price'] > 0]\nbasket_price.sort_values('CustomerID')[:6]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"25044f79-9cef-464a-9b7c-59eec5dac316","_uuid":"2365eaa0e1a3d4d505f7261c8139e04f276301eb"},"cell_type":"markdown","source":"In order to have a global view of the type of order performed in this dataset, I determine how the purchases are divided according to total prizes:"},{"metadata":{"_cell_guid":"25f72313-bc56-4a10-99b1-243f147b1756","_kg_hide-input":true,"_uuid":"b1b30be7aa80d7a5287e6fd783b5d8cdbff4032d","trusted":true},"cell_type":"code","source":"# uneven binning of the basket_price\nprice_range = [0, 50, 100, 200, 500, 1000, 5000, 50000]\ncount_price = []\nfor i, price in enumerate(price_range):\n    if i == 0: \n        continue\n    val = basket_price[(basket_price['Basket Price'] < price) &\n                       (basket_price['Basket Price'] > price_range[i-1])]['Basket Price'].count()\n    count_price.append(val)\n\n# plot a pie chart\nplt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(11, 6))\ncolors = ['firebrick', 'royalblue', 'orange', 'c', 'violet', 'gold','yellowgreen']\nlabels = [ '{}<.<{}'.format(price_range[i-1], s) for i,s in enumerate(price_range) if i != 0]\nsizes  = count_price\nexplode = [0.0 if sizes[i] < 100 else 0.0 for i in range(len(sizes))]\nax.pie(sizes, explode = explode, labels=labels, colors = colors,\n       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n       shadow = False, startangle=0)\nax.axis('equal')\nf.text(0.5, 1.01, \"Distribution of order amounts\", ha='center', fontsize = 18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now want to cluster our products. For that, we first need to find the categories. To find the categories we apply NLP techniques on the decription column of the dataset."},{"metadata":{"_cell_guid":"62aada7f-1d61-493e-a044-08fcc7bdfb81","_kg_hide-input":true,"_uuid":"4ae364672f6cede623fd0e032e34d967e4f32ee1","trusted":true},"cell_type":"code","source":"is_noun = lambda pos: pos[:2] == 'NN'\n\ndef keywords_inventory(dataframe, column = 'Description'):\n    stemmer = nltk.stem.SnowballStemmer(\"english\")\n    keywords_roots  = dict()  \n    keywords_select = dict()  \n    category_keys   = []\n    count_keywords  = dict()\n    icount = 0\n    for s in dataframe[column]:\n        if pd.isnull(s): \n            continue\n        lines = s.lower()\n        tokenized = nltk.word_tokenize(lines)\n        nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n        \n        for t in nouns:\n            t = t.lower() ; stemmed_word = stemmer.stem(t)\n            if stemmed_word in keywords_roots:                \n                keywords_roots[stemmed_word].add(t)\n                count_keywords[stemmed_word] += 1                \n            else:\n                keywords_roots[stemmed_word] = {t}\n                count_keywords[stemmed_word] = 1\n    \n    for s in keywords_roots.keys():\n        if len(keywords_roots[s]) > 1:  \n            min_length = 1000\n            for k in keywords_roots[s]:\n                if len(k) < min_length:\n                    min_length_word = k ; min_length = len(k)            \n            category_keys.append(min_length_word)\n            keywords_select[s] = min_length_word\n        else:\n            category_keys.append(list(keywords_roots[s])[0])\n            keywords_select[s] = list(keywords_roots[s])[0]\n                   \n    print(\"No of keywords in variable '{}': {}\".format(column,len(category_keys)))\n    return category_keys, keywords_roots, keywords_select, count_keywords","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f4da3052-c465-47bf-9652-a10a8ac51eb6","_kg_hide-input":true,"_uuid":"1239a65ae122b1c020db626e5167451a950d8226","trusted":true},"cell_type":"code","source":"df_products = pd.DataFrame(df_initial['Description'].unique()).rename(columns = {0:'Description'})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f52a4134-c9c7-4d17-8510-8f55b1530cbb","_kg_hide-input":true,"_uuid":"38c4872616b2c40bf69982070165cc9db3d0ea69","trusted":true},"cell_type":"code","source":"keywords, keywords_roots, keywords_select, count_keywords = keywords_inventory(df_products)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e033781a-8038-4302-93ed-78966554b7cc","_kg_hide-input":true,"_uuid":"66fb955b137916f16d838f95a6f5bbe5e4952334","trusted":true},"cell_type":"code","source":"list_products = []\nfor k,v in count_keywords.items():\n    list_products.append([keywords_select[k],v])\nlist_products.sort(key = lambda x:x[1], reverse = True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d6c78812-343e-41af-8e4e-ef0292dc4f7e","_kg_hide-input":true,"_uuid":"fcdf4d98e372a1d65c931b7a6d5c29f269938022","trusted":true},"cell_type":"code","source":"# plot word occurences\ncount_sorted_word_list = sorted(list_products, key = lambda x:x[1], reverse = True)\nplt.rc('font', weight='normal')\nfig, ax = plt.subplots(figsize=(7, 25))\ny_axis = [i[1] for i in count_sorted_word_list[:125]]\nx_axis = [k for k,i in enumerate(count_sorted_word_list[:125])]\nx_label = [i[0] for i in count_sorted_word_list[:125]]\nplt.xticks(fontsize = 15)\nplt.yticks(fontsize = 13)\nplt.yticks(x_axis, x_label)\nplt.xlabel(\"No. of occurences\", fontsize = 18, labelpad = 10)\nax.barh(x_axis, y_axis, align = 'center')\nax = plt.gca()\nax.invert_yaxis()\nplt.title(\"Words occurence\",bbox={'facecolor':'k', 'pad':5}, color='w',fontsize = 25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba5e6966-49e7-4a3d-84cf-9fe809e8315b","_uuid":"5f375df32988b2bb559c77ad5c8d244472ae39f4"},"cell_type":"markdown","source":"We use words having frequency more than 13 as categories and length greater than 3 as categories"},{"metadata":{"_cell_guid":"43300478-3b5a-4c7a-9466-34c384ccae60","_kg_hide-input":true,"_uuid":"5f42482995f36f15688d8cba7f903e1277da5f92","trusted":true},"cell_type":"code","source":"#removing irrelevant words\nlist_products = []\nfor k,v in count_keywords.items():\n    word = keywords_select[k]\n    if word in ['pink', 'blue', 'tag', 'green', 'orange']: \n        continue\n    if len(word) < 3 or v < 13: \n        continue\n    if ('+' in word) or ('/' in word): \n        continue\n    list_products.append([word, v])\nlist_products.sort(key = lambda x:x[1], reverse = True)\nprint('preserved words:', len(list_products))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"23c77363-438b-4694-9b52-960c0ab3aa82","_kg_hide-input":true,"_uuid":"d6faac7eb01d2251fb221569b75e007c8d5146aa","trusted":true},"cell_type":"code","source":"# Each category is checked against each description\n# Ex: All descriptions are checked for glass being present in them\nlist_products_cleaned = df_cleaned['Description'].unique()\nX = pd.DataFrame()\nfor key, occurence in list_products:\n    X.loc[:, key] = list(map(lambda x:int(key.upper() in x), list_products_cleaned))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"739c9cb1-3278-4d3a-a412-25dd2e8bc7c4","_kg_hide-input":true,"_uuid":"b26a6bc55b61d0bcaccaf7c303b90d2a04636ac4","trusted":true},"cell_type":"code","source":"# finding mean unit price of each product category and binning it\nthreshold = [0, 1, 2, 3, 5, 10]\nlabel_col = []\nfor i in range(len(threshold)):\n    if i == len(threshold)-1:\n        col = '.>{}'.format(threshold[i])\n    else:\n        col = '{}<.<{}'.format(threshold[i],threshold[i+1])\n    label_col.append(col)\n    \n    # Iniliazlizing\n    X.loc[:, col] = 0\n\nfor i, prod in enumerate(list_products_cleaned):\n    prix = df_cleaned[ df_cleaned['Description'] == prod]['UnitPrice'].mean()\n    j = 0\n    while prix > threshold[j]:\n        j+=1\n        if j == len(threshold): break\n    X.loc[i, label_col[j-1]] = 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5c1ac4b1-3bfa-4aac-8329-d5d923f7d08d","_uuid":"d6551f396773df6fbf7a49a9985583d20e6a58be"},"cell_type":"markdown","source":"and to choose the appropriate ranges, I check the number of products in the different groups:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8587b9a3-d3a6-41ed-ac8a-9e0cdc9af31e","_kg_hide-input":true,"_uuid":"6ad9fc6ed72057c63594d9d97d89742202f064f7","trusted":true},"cell_type":"code","source":"print(\"{:<8} {:<20} \\n\".format('Range', 'No. of products') + 20*'-')\nfor i in range(len(threshold)):\n    if i == len(threshold)-1:\n        col = '.>{}'.format(threshold[i])\n    else:\n        col = '{}<.<{}'.format(threshold[i],threshold[i+1])    \n    print(\"{:<10}  {:<20}\".format(col, X.loc[:, col].sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The product data is categorical. KModes clustering algorithm uses Hamming distance as a distance measure, it performs better than KMeans algorithm at clustering categorical dataset."},{"metadata":{"_cell_guid":"1c81a7c3-8980-4941-9082-7bf5cf92fc14","_kg_hide-input":true,"_uuid":"4ce8586584935e81b9e403ea7a1dd4b2e4c9992e","trusted":true},"cell_type":"code","source":"matrix = X.as_matrix()\nfor n_clusters in range(3,10):        \n    km = KModes(n_clusters = n_clusters, init='Huang', n_init=2, verbose=0)\n    clusters = km.fit_predict(matrix)\n    silhouette_avg = silhouette_score(matrix, clusters)\n    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b29b3bb2-ef8d-4d7f-a19e-52045018ab8e","_kg_hide-input":true,"_uuid":"72dd5bdab528264518bf034b84f66f3c29500fca","trusted":true},"cell_type":"code","source":"# The following code can be uncommented to get KModes model with silhoutte score of > 0.13\n\n# n_clusters = 7\n# silhouette_avg = -1\n# max_sil_avg = -1\n# count = 0\n# while ((silhouette_avg < 0.13) and (count < 10)):\n#     km = KModes(n_clusters = n_clusters, init='Huang', n_init=2, verbose=0)\n#     clusters = km.fit_predict(matrix)\n#     silhouette_avg = silhouette_score(matrix, clusters)\n#     print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n#     if(silhouette_avg > max_sil_avg):\n#         max_sil_avg = silhouette_avg\n#         pkl_fl_name = '/kaggle/working/product_kmodes_clustering.pickle'\n#         pkl_fl_handle = open(pkl_fl_name, 'wb')\n#         pickle.dump(km, pkl_fl_handle)\n#         pkl_fl_handle.close()\n#     count += 1\n    \n# print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad66161e-87ba-42ca-8128-bda16b470a34","_kg_hide-input":true,"_uuid":"83591dd72975afde6a85d70429add02bd278c125","trusted":true},"cell_type":"code","source":"pd.Series(clusters).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c2b26710-2269-47e5-8f0d-98f6eac0015a","_kg_hide-input":true,"_uuid":"e9e48bbbc3bb0ffa8134175aefb1fe808dea33e8","trusted":true},"cell_type":"code","source":"# def graph_component_silhouette(n_clusters, lim_x, mat_size, sample_silhouette_values, clusters):\n#     plt.rcParams[\"patch.force_edgecolor\"] = True\n#     plt.style.use('fivethirtyeight')\n#     mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n#     #____________________________\n#     fig, ax1 = plt.subplots(1, 1)\n#     fig.set_size_inches(8, 8)\n#     ax1.set_xlim([lim_x[0], lim_x[1]])\n#     ax1.set_ylim([0, mat_size + (n_clusters + 1) * 10])\n#     y_lower = 10\n#     for i in range(n_clusters):\n#         #___________________________________________________________________________________\n#         # Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n#         ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]\n#         ith_cluster_silhouette_values.sort()\n#         size_cluster_i = ith_cluster_silhouette_values.shape[0]\n#         y_upper = y_lower + size_cluster_i\n#         cmap = cm.get_cmap(\"Spectral\")\n#         color = cmap(float(i) / n_clusters)        \n#         ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n#                            facecolor=color, edgecolor=color, alpha=0.8)\n#         #____________________________________________________________________\n#         # Label the silhouette plots with their cluster numbers at the middle\n#         ax1.text(-0.03, y_lower + 0.5 * size_cluster_i, str(i), color = 'red', fontweight = 'bold',\n#                 bbox=dict(facecolor='white', edgecolor='black', boxstyle='round, pad=0.3'))\n#         #______________________________________\n#         # Compute the new y_lower for next plot\n#         y_lower = y_upper + 10  ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ee417cb-29d9-4913-8e12-0c020ecde059","_kg_hide-input":true,"_uuid":"cf9b40ed0d865401e4a05e06eec2bff97ace7059","trusted":true},"cell_type":"code","source":"# #____________________________________\n# # define individual silouhette scores\n# sample_silhouette_values = silhouette_samples(matrix, clusters)\n# #__________________\n# # and do the graph\n# graph_component_silhouette(n_clusters, [-0.07, 0.33], len(X), sample_silhouette_values, clusters)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"159600b4-def2-4e4d-be54-6d84938721c4","_kg_hide-input":true,"_uuid":"848009ae647f20366e148eeae96a4aa02f975618","trusted":true},"cell_type":"code","source":"count_sorted_word_list = pd.DataFrame(list_products_cleaned)\nlist_words = [word for (word, occurence) in list_products]\n\noccurence = [dict() for _ in range(n_clusters)]\n\nfor i in range(n_clusters):\n    liste_cluster = count_sorted_word_list.loc[clusters == i]\n    for word in list_words:\n        if word in ['art', 'set', 'heart', 'pink', 'blue', 'tag']: continue\n        occurence[i][word] = sum(liste_cluster.loc[:, 0].str.contains(word.upper()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2995e126-925b-436f-8b68-55d874637b1e","_kg_hide-input":true,"_uuid":"3d88a32f7998249ce42e267bb912acc7420f0c47","trusted":true},"cell_type":"code","source":"def random_color_func(word=None, font_size=None, position=None,\n                      orientation=None, font_path=None, random_state=None):\n    h = int(360.0 * tone / 255.0)\n    s = int(100.0 * 255.0 / 255.0)\n    l = int(100.0 * float(random_state.randint(70, 120)) / 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\ndef make_wordcloud(liste, increment):\n    ax1 = fig.add_subplot(4,2,increment)\n    words = dict()\n    trunc_occurences = liste[0:150]\n    for s in trunc_occurences:\n        words[s[0]] = s[1]\n\n    wordcloud = WordCloud(width=1000,height=400, background_color='lightgrey', \n                          max_words=1628,relative_scaling=1,\n                          color_func = random_color_func,\n                          normalize_plurals=False)\n    wordcloud.generate_from_frequencies(words)\n    ax1.imshow(wordcloud, interpolation=\"bilinear\")\n    ax1.axis('off')\n    plt.title('cluster nº{}'.format(increment-1))\n\nfig = plt.figure(1, figsize=(14,14))\ncolor = [0, 160, 130, 95, 280, 40, 330, 110, 25]\nfor i in range(n_clusters):\n    list_cluster_occurences = occurence[i]\n\n    tone = color[i] \n    temp_list = []\n    for key, value in list_cluster_occurences.items():\n        temp_list.append([key, value])\n    temp_list.sort(key = lambda x:x[1], reverse = True)\n    make_wordcloud(temp_list, i+1)            ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"85af75c5-bf90-4b8c-9687-caff723d0027","_kg_hide-input":true,"_uuid":"33859d205bcf40477d166b679fb97996ba2d5f48","trusted":true},"cell_type":"code","source":"pca = PCA()\npca.fit(matrix)\npca_samples = pca.transform(matrix)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"41cd8738-4923-43cd-b26a-fba6d53070e8","_kg_hide-input":true,"_uuid":"abce52d76e801aa6197603925618fb032aec78af","trusted":true},"cell_type":"code","source":"# checking variance explained by each principal component\nfig, ax = plt.subplots(figsize=(14, 5))\nsns.set(font_scale=1)\nplt.step(range(matrix.shape[1]), pca.explained_variance_ratio_.cumsum(), where='mid',\n         label='cumulative explained variance')\nsns.barplot(np.arange(1,matrix.shape[1]+1), pca.explained_variance_ratio_, alpha=0.5, color = 'g',\n            label='individual explained variance')\nplt.xlim(0, 100)\n\nax.set_xticklabels([s if int(s.get_text())%2 == 0 else '' for s in ax.get_xticklabels()])\n\nplt.ylabel('Explained variance', fontsize = 14)\nplt.xlabel('Principal components', fontsize = 14)\nplt.legend(loc='upper left', fontsize = 13);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we need about 100 components to explain 90% of the variance, we arbitrarily choose only 50 of them"},{"metadata":{"_cell_guid":"0e49b019-d1b7-4815-8c5e-7cf27fa5b5b2","_kg_hide-input":true,"_uuid":"fb0afe8523c2634860fdaf67d734c1dc0897c4c0","trusted":true},"cell_type":"code","source":"pca = PCA(n_components=50)\nmatrix_9D = pca.fit_transform(matrix)\nmat = pd.DataFrame(matrix_9D)\nmat['cluster'] = pd.Series(clusters)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"675cc670-4512-4983-8b58-e82f3cf2bf3d","_kg_hide-input":true,"_uuid":"b9d872fa5038458f3424dfc585a5a823efc7ff7f","trusted":true},"cell_type":"code","source":"# import matplotlib.patches as mpatches\n\n# sns.set_style(\"white\")\n# sns.set_context(\"notebook\", font_scale=1, rc={\"lines.linewidth\": 2.5})\n\n# LABEL_COLOR_MAP = {0:'r', 1:'gold', 2:'b', 3:'k', 4:'c', 5:'g'}\n# label_color = [LABEL_COLOR_MAP[l] for l in mat['cluster']]\n\n# fig = plt.figure(figsize = (15,8))\n# increment = 0\n# for ix in range(4):\n#     for iy in range(ix+1, 4):    \n#         increment += 1\n#         ax = fig.add_subplot(2,3,increment)\n#         ax.scatter(mat[ix], mat[iy], c= label_color, alpha=0.4) \n#         plt.ylabel('PCA {}'.format(iy+1), fontsize = 12)\n#         plt.xlabel('PCA {}'.format(ix+1), fontsize = 12)\n#         ax.yaxis.grid(color='lightgray', linestyle=':')\n#         ax.xaxis.grid(color='lightgray', linestyle=':')\n#         ax.spines['right'].set_visible(False)\n#         ax.spines['top'].set_visible(False)\n        \n#         if increment == 9: break\n#     if increment == 9: break\n        \n# #_______________________________________________\n# # I set the legend: abreviation -> airline name\n# comp_handler = []\n# for i in range(5):\n#     comp_handler.append(mpatches.Patch(color = LABEL_COLOR_MAP[i], label = i))\n\n# plt.legend(handles=comp_handler, bbox_to_anchor=(1.1, 0.97), \n#            title='Cluster', facecolor = 'lightgrey',\n#            shadow = True, frameon = True, framealpha = 1,\n#            fontsize = 13, bbox_transform = plt.gcf().transFigure)\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b66c0817-22c1-42cf-b944-8e3db918a671","_kg_hide-input":true,"_uuid":"c030102cce28bbf7e268ed40b0388017cd15df8f","trusted":true},"cell_type":"code","source":"corresp = dict()\nfor key, val in zip (list_products_cleaned, clusters):\n    corresp[key] = val \n#__________________________________________________________________________\ndf_cleaned['categ_product'] = df_cleaned.loc[:, 'Description'].map(corresp)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"882978a7-8d65-468e-982a-dd689515d415","_kg_hide-input":true,"_uuid":"7b29ea4de78cdf757e031a0d810b24c4a3641057","trusted":true},"cell_type":"code","source":"for i in range(7):\n    col = 'categ_{}'.format(i)        \n    df_temp = df_cleaned[df_cleaned['categ_product'] == i]\n    price_temp = df_temp['UnitPrice'] * (df_temp['Quantity'] - df_temp['QuantityCancelled'])\n    price_temp = price_temp.apply(lambda x:x if x > 0 else 0)\n    df_cleaned.loc[:, col] = price_temp\n    df_cleaned[col].fillna(0, inplace = True)\n\ndf_cleaned[['InvoiceNo', 'Description', 'categ_product', 'categ_0', 'categ_1', 'categ_2', 'categ_3','categ_4','categ_5','categ_6']][:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9a5249e1-7ac8-43f9-a759-db4df4934e71","_kg_hide-input":true,"_uuid":"9d0c9edb309503999f38ccc40fd09d1a311a5019","trusted":true},"cell_type":"code","source":"# sum of purchases / user & order\ntemp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\nbasket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\n\n# percentage of the price of the order / product category\nfor i in range(7):\n    col = 'categ_{}'.format(i) \n    temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)[col].sum()\n    basket_price.loc[:, col] = temp \n\n# date of the order\ndf_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\ntemp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\ndf_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\nbasket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])\n\n# selection of significant entries:\nbasket_price = basket_price[basket_price['Basket Price'] > 0]\nbasket_price.sort_values('CustomerID', ascending = True)[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now split the data into 2 parts - data of first 10 months for training and data of last 2 months for testing"},{"metadata":{"_cell_guid":"c30fa4af-6617-4e25-b297-23efae5e1dcb","_kg_hide-input":true,"_uuid":"7be642cc67d95c7b149747f66a8ba8845a17350e","trusted":true},"cell_type":"code","source":"print(basket_price['InvoiceDate'].min(), '->',  basket_price['InvoiceDate'].max())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29948719-cecf-48d3-ab66-ca76214b058a","_kg_hide-input":true,"_uuid":"854a1781838e9d4f9e2a27e6a0b65c5e86d7a1b0","trusted":true},"cell_type":"code","source":"set_train = basket_price[basket_price['InvoiceDate'] < datetime.date(2011,10,1)]\nset_test         = basket_price[basket_price['InvoiceDate'] >= datetime.date(2011,10,1)]\nbasket_price = set_train.copy(deep = True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"876435e3-49c7-4f98-a58f-55d8f0620ef8","_kg_hide-input":true,"_uuid":"a8144451cb606fde4e691486ea9b9d2ccbeae7b9","trusted":true},"cell_type":"code","source":"# of visits and stats on cart amount / users\ntransactions_per_user=basket_price.groupby(by=['CustomerID'])['Basket Price'].agg(['count','min','max','mean','sum'])\nfor i in range(7):\n    col = 'categ_{}'.format(i)\n    transactions_per_user.loc[:,col] = basket_price.groupby(by=['CustomerID'])[col].sum() /\\\n                                            transactions_per_user['sum']*100\n\ntransactions_per_user.reset_index(drop = False, inplace = True)\nbasket_price.groupby(by=['CustomerID'])['categ_0'].sum()\ntransactions_per_user.sort_values('CustomerID', ascending = True)[:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c02d86a5-f239-4ec0-9374-61a000f81ec7","_uuid":"cd335b44bdd24a675ee3407580171135a1053649"},"cell_type":"markdown","source":"Finally, I define two additional variables that give the number of days elapsed since the first purchase (** FirstPurchase **) and the number of days since the last purchase (** LastPurchase **):"},{"metadata":{"_cell_guid":"60a47c3b-b36a-460a-835b-7f6d3c7af48c","_kg_hide-input":true,"_uuid":"29dab7aeb0f6d8d1e898b9d72efa2a6e07f1d3e0","scrolled":true,"trusted":true},"cell_type":"code","source":"# number of days elapsed since the first purchase and the number of days since the last purchase\nlast_date = basket_price['InvoiceDate'].max().date()\n\nfirst_registration = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].min())\nlast_purchase      = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].max())\n\ntest  = first_registration.applymap(lambda x:(last_date - x.date()).days)\ntest2 = last_purchase.applymap(lambda x:(last_date - x.date()).days)\n\ntransactions_per_user.loc[:, 'LastPurchase'] = test2.reset_index(drop = False)['InvoiceDate']\ntransactions_per_user.loc[:, 'FirstPurchase'] = test.reset_index(drop = False)['InvoiceDate']\n\ntransactions_per_user[:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f0a8717e-bf13-4847-a2d8-d5c518ef7580","_kg_hide-input":true,"_uuid":"27a45dcd6d0ac2382f07ef6b091a50fc7006a389","trusted":true},"cell_type":"code","source":"n1 = transactions_per_user[transactions_per_user['count'] == 1].shape[0]\nn2 = transactions_per_user.shape[0]\nprint(\"No. of customers with single purchase: {:<2}/{:<5} ({:<2.2f}%)\".format(n1,n2,n1/n2*100))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cdc3d67f-1337-4cf6-8a36-7b99d4adc160","_kg_hide-input":true,"_uuid":"1769df5bd3f987760e0493c6979c9031e18cd47e","trusted":true},"cell_type":"code","source":"list_cols = ['count','min','max','mean','categ_0','categ_1','categ_2','categ_3','categ_4','categ_5','categ_6']\n\nselected_customers = transactions_per_user.copy(deep = True)\nmatrix = selected_customers[list_cols].as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"84be0db9-a24a-4b9b-b541-e1437404ff37","_kg_hide-input":true,"_uuid":"5e15c98b0da14a1fe5473ca2fa6c5722968386b6","trusted":true},"cell_type":"code","source":"# normalizing the feature matrix\nscaler = StandardScaler()\nscaler.fit(matrix)\nprint('variables mean values: \\n' + 90*'-' + '\\n' , scaler.mean_)\nscaled_matrix = scaler.transform(matrix)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"302061b0-4e19-4b5b-a969-1f45c27873e1","_kg_hide-input":true,"_uuid":"30b6a47f96e223efeb0ab49517b38c192627927f","trusted":true},"cell_type":"code","source":"pca = PCA()\npca.fit(scaled_matrix)\npca_samples = pca.transform(scaled_matrix)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ed6ab99d-fee5-44c3-958c-58b786263e82","_kg_hide-input":true,"_uuid":"bb95db84567cb2a3a32652bcf2b3ea5c14b5b550","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 5))\nsns.set(font_scale=1)\nplt.step(range(matrix.shape[1]), pca.explained_variance_ratio_.cumsum(), where='mid',\n         label='cumulative explained variance')\nsns.barplot(np.arange(1,matrix.shape[1]+1), pca.explained_variance_ratio_, alpha=0.5, color = 'g',\n            label='individual explained variance')\nplt.xlim(0, 10)\n\nax.set_xticklabels([s if int(s.get_text())%2 == 0 else '' for s in ax.get_xticklabels()])\n\nplt.ylabel('Explained variance', fontsize = 14)\nplt.xlabel('Principal components', fontsize = 14)\nplt.legend(loc='best', fontsize = 13);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We tried varied number of clusters ranging from 7 (no of product categories) to 15. We got the best silhouette score when we assume 11 clusters"},{"metadata":{"_cell_guid":"ce1adb5f-a0cf-4af4-99fa-585fa71cf89f","_kg_hide-input":true,"_uuid":"09711facb0d6dd1e4027724a55b8a5fa0155b616","trusted":true},"cell_type":"code","source":"n_clusters = 11\nkmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=100)\nkmeans.fit(scaled_matrix)\nclusters_clients = kmeans.predict(scaled_matrix)\nsilhouette_avg = silhouette_score(scaled_matrix, clusters_clients)\nprint('Avg silhouette score: {:<.3f}'.format(silhouette_avg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# km_pickle_file = '/kaggle/working/customer_km.pickle'\n# x = open(lr_pickle_file, 'wb')\n# pickle.dump(l, x)\n# x.close()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7e64fcb6-4827-4bb9-883e-f31e9c595dba","_kg_hide-input":true,"_uuid":"b1f770e4ac40cc0e868efb12f895653fb5127599","scrolled":true,"trusted":true},"cell_type":"code","source":"pd.DataFrame(pd.Series(clusters_clients).value_counts(), columns = ['No. of clients']).T","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"051ee4e8-78a1-48d9-aa43-84e089a57df3","_kg_hide-input":true,"_uuid":"716227b8a446ac77c9397893964c782333a02e6a","trusted":true},"cell_type":"code","source":"pca = PCA(n_components=6)\nmatrix_3D = pca.fit_transform(scaled_matrix)\nmat = pd.DataFrame(matrix_3D)\nmat['cluster'] = pd.Series(clusters_clients)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1c45a7fd-b564-4595-b725-0d0ae03a25e7","_uuid":"52f45c0a955a33a52c812aaf9e60e5a82f5bd2da","trusted":true},"cell_type":"code","source":"# The clustering done is hard clustering and hence each customer belongs to just one cluster. We add the cluster column as the target column in the dataframe\nselected_customers.loc[:, 'cluster'] = clusters_clients","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"edaa1b78-74be-44cf-952d-f5148824b5d8","_kg_hide-input":true,"_uuid":"0fb5e92a263ea5290cfe72fb03257ea6eff632ce","scrolled":true,"trusted":true},"cell_type":"code","source":"merged_df = pd.DataFrame()\nfor i in range(n_clusters):\n    test = pd.DataFrame(selected_customers[selected_customers['cluster'] == i].mean())\n    test = test.T.set_index('cluster', drop = True)\n    test['size'] = selected_customers[selected_customers['cluster'] == i].shape[0]\n    merged_df = pd.concat([merged_df, test])\n#_____________________________________________________\nmerged_df.drop('CustomerID', axis = 1, inplace = True)\nprint('number of customers:', merged_df['size'].sum())\n\nmerged_df = merged_df.sort_values('sum')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e544d9cd-9589-46e8-9af5-3ad59a193b6b","_kg_hide-input":true,"_uuid":"3d7b1bbb5feb7c4e5ab1e48a27104b5fa51cbac4","trusted":true},"cell_type":"code","source":"def _scale_data(data, ranges):\n    (x1, x2) = ranges[0]\n    d = data[0]\n    return [(d - y1) / (y2 - y1) * (x2 - x1) + x1 for d, (y1, y2) in zip(data, ranges)]\n\nclass RadarChart():\n    def __init__(self, fig, location, sizes, variables, ranges, n_ordinate_levels = 6):\n\n        angles = np.arange(0, 360, 360./len(variables))\n\n        ix, iy = location[:] ; size_x, size_y = sizes[:]\n        \n        axes = [fig.add_axes([ix, iy, size_x, size_y], polar = True, \n        label = \"axes{}\".format(i)) for i in range(len(variables))]\n\n        _, text = axes[0].set_thetagrids(angles, labels = variables)\n        \n        for txt, angle in zip(text, angles):\n            if angle > -1 and angle < 181:\n                txt.set_rotation(angle - 90)\n            else:\n                txt.set_rotation(angle - 270)\n        \n        for ax in axes[1:]:\n            ax.patch.set_visible(False)\n            ax.xaxis.set_visible(False)\n            ax.grid(\"off\")\n        \n        for i, ax in enumerate(axes):\n            grid = np.linspace(*ranges[i],num = n_ordinate_levels)\n            grid_label = [\"\"]+[\"{:.0f}\".format(x) for x in grid[1:-1]]\n            ax.set_rgrids(grid, labels = grid_label, angle = angles[i])\n            ax.set_ylim(*ranges[i])\n        \n        self.angle = np.deg2rad(np.r_[angles, angles[0]])\n        self.ranges = ranges\n        self.ax = axes[0]\n                \n    def plot(self, data, *args, **kw):\n        sdata = _scale_data(data, self.ranges)\n        self.ax.plot(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n\n    def fill(self, data, *args, **kw):\n        sdata = _scale_data(data, self.ranges)\n        self.ax.fill(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n\n    def legend(self, *args, **kw):\n        self.ax.legend(*args, **kw)\n        \n    def title(self, title, *args, **kw):\n        self.ax.text(0.9, 1, title, transform = self.ax.transAxes, *args, **kw)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"231c1e12-c833-43ae-86e2-4f32b48c5bb1","_uuid":"fb503c92e6a1ac8f4a6aa6d2136ec94e69a4de48"},"cell_type":"markdown","source":"This allows to have a global view of the content of each cluster:"},{"metadata":{"_cell_guid":"d0066031-e494-407f-9e9f-b79167244fd1","_kg_hide-input":true,"_uuid":"3074b64fa2e091118783baa4452fe7ccc22c82cb","trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,12))\n\nattributes = ['count', 'mean', 'sum', 'categ_0', 'categ_1', 'categ_2', 'categ_3', 'categ_4', 'categ_5', 'categ_6']\nranges = [[0.01, 10], [0.01, 1500], [0.01, 10000], [0.01, 75], [0.01, 75], [0.01, 75], [0.01, 75], [0.01, 75], [0.01, 75], [0.01, 75]]\nindex  = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n\nn_groups = n_clusters ; i_cols = 3\ni_rows = n_groups//i_cols\nsize_x, size_y = (1/i_cols), (1/i_rows)\n\nfor ind in range(n_clusters):\n    ix = ind%3 ; iy = i_rows - ind//3\n    pos_x = ix*(size_x + 0.05) ; pos_y = iy*(size_y + 0.05)            \n    location = [pos_x, pos_y]  ; sizes = [size_x, size_y] \n    #______________________________________________________\n    data = np.array(merged_df.loc[index[ind], attributes])    \n    radar = RadarChart(fig, location, sizes, attributes, ranges)\n    radar.plot(data, color = 'b', linewidth=2.0)\n    radar.fill(data, alpha = 0.2, color = 'b')\n    radar.title(title = 'cluster nº{}'.format(index[ind]), color = 'r')\n    ind += 1 ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13991b6e-7070-4e99-985a-8955cd995840","_kg_hide-input":true,"_uuid":"33233378b919c14b0b43dd7bb8f5b7023ccb089a","trusted":true},"cell_type":"code","source":"class Class_Fit(object):\n    def __init__(self, clf, params=None):\n        if params:            \n            self.clf = clf(**params)\n        else:\n            self.clf = clf()\n\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n\n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def grid_search(self, parameters, Kfold):\n        self.grid = GridSearchCV(estimator = self.clf, param_grid = parameters, cv = Kfold)\n        \n    def grid_fit(self, X, Y):\n        self.grid.fit(X, Y)\n        \n    def grid_predict(self, X, Y):\n        self.predictions = self.grid.predict(X)\n        print(\"Precision: {:.2f} % \".format(100*metrics.accuracy_score(Y, self.predictions)))\n        ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5bdd768a-8cb4-49dc-84fc-33c8b84a3362","_kg_hide-input":true,"_uuid":"df64b250e989c1a33fe31921ee308056fc5a57b5","trusted":true},"cell_type":"code","source":"columns = ['mean', 'categ_0', 'categ_1', 'categ_2', 'categ_3', 'categ_4', 'categ_5', 'categ_6' ]\nX = selected_customers[columns]\nY = selected_customers['cluster']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c9c4174c-bd28-47df-9919-e951f45bd7f2","_kg_hide-input":true,"_uuid":"43c2d31561df475b5c56f5123c3d1080ed3990a2","trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size = 0.8)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c37cd77b-f96d-483b-bb57-14db65f97039","_kg_hide-input":true,"_uuid":"9ee59b5060327224a4356be75ee1221b4e9fb0ab","trusted":true},"cell_type":"code","source":"lr = Class_Fit(clf = linear_model.LogisticRegression)\nlr.grid_search(parameters = [{'C':np.logspace(-2,2,20)}], Kfold = 5)\nlr.grid_fit(X = X_train, Y = Y_train)\nlr.grid_predict(X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr_pickle_file = '/kaggle/working/customer_lr.pickle'\n# x = open(lr_pickle_file, 'wb')\n# pickle.dump(lr, x)\n# x.close()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8c4c95f0-8116-4501-ae86-7df54fa6a8dd","_kg_hide-input":true,"_uuid":"203206e691175e8ff82cf72cfb34e82ffd2acf0c","trusted":true},"cell_type":"code","source":"g = plot_learning_curve(lr.grid.best_estimator_, \"Logistic Regression learning curves\", X_train, Y_train,\n                        ylim = [1.01, 0.7], cv = 5, \n                        train_sizes = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}